{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de408378fa7f896",
   "metadata": {},
   "source": [
    "# Trabajo Pr\u00e1ctico: Exploraci\u00f3n y Preparaci\u00f3n de Airbnb Listings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25168aa8f005c13d",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "En esta libreta analizamos el dataset `listings_big.csv` para comprender su estructura, diagnosticar problemas de calidad y preparar un conjunto de features apto para estimar **qu\u00e9 tan alquilable es un listing**. El flujo general incluye:\n",
    "- Exploraci\u00f3n inicial y resumen estad\u00edstico\n",
    "- An\u00e1lisis de valores faltantes y patrones de disponibilidad\n",
    "- Visualizaciones que permitan interpretar la ocupaci\u00f3n y sus drivers\n",
    "- Definici\u00f3n de un problema supervisado de clasificaci\u00f3n enfocado en la alta ocupaci\u00f3n\n",
    "- Construcci\u00f3n de un pipeline de preprocesamiento, ingenier\u00eda de variables y selecci\u00f3n/reducci\u00f3n de dimensionalidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5084600",
   "metadata": {},
   "source": [
    "# \ud83c\udfe1 Airbnb Listings Data Dictionary\n",
    "\n",
    "> Diccionario de datos del conjunto de listados de Airbnb, con tipos de datos, campos calculados y descripciones.  \n",
    "> Compatible con visualizaci\u00f3n en GitHub (scroll horizontal autom\u00e1tico en tablas grandes).\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"overflow-x: auto;\">\n",
    "\n",
    "| **Field** | **Type** | **Calculated** | **Description** |\n",
    "|------------|-----------|----------------|-----------------|\n",
    "| id | integer |  | Airbnb's unique identifier for the listing |\n",
    "| listing_url | text | \u2705 |  |\n",
    "| scrape_id | bigint | \u2705 | Inside Airbnb \"Scrape\" this was part of |\n",
    "| last_scraped | datetime | \u2705 | UTC. The date and time this listing was \"scraped\". |\n",
    "| source | text |  | One of `\"neighbourhood search\"` or `\"previous scrape\"`. Describes how the listing was discovered. |\n",
    "| name | text |  | Name of the listing |\n",
    "| description | text |  | Detailed description of the listing |\n",
    "| neighborhood_overview | text |  | Host's description of the neighbourhood |\n",
    "| picture_url | text |  | URL to Airbnb-hosted regular-sized image |\n",
    "| host_id | integer |  | Airbnb's unique identifier for the host/user |\n",
    "| host_url | text | \u2705 | Airbnb page for the host |\n",
    "| host_name | text |  | Name of the host (usually first name). |\n",
    "| host_since | date |  | Host account creation date |\n",
    "| host_location | text |  | Host's self-reported location |\n",
    "| host_about | text |  | Description about the host |\n",
    "| host_response_time | text |  |  |\n",
    "| host_response_rate | text |  |  |\n",
    "| host_acceptance_rate | text |  | Rate at which host accepts booking requests |\n",
    "| host_is_superhost | boolean *(t=true; f=false)* |  |  |\n",
    "| host_thumbnail_url | text |  |  |\n",
    "| host_picture_url | text |  |  |\n",
    "| host_neighbourhood | text |  |  |\n",
    "| host_listings_count | text |  | Number of listings (Airbnb internal) |\n",
    "| host_total_listings_count | text |  | Total listings (Airbnb internal) |\n",
    "| host_verifications | text |  |  |\n",
    "| host_has_profile_pic | boolean *(t=true; f=false)* |  |  |\n",
    "| host_identity_verified | boolean *(t=true; f=false)* |  |  |\n",
    "| neighbourhood | text |  |  |\n",
    "| neighbourhood_cleansed | text | \u2705 | Geocoded neighbourhood (from shapefiles) |\n",
    "| neighbourhood_group_cleansed | text | \u2705 | Geocoded neighbourhood group (from shapefiles) |\n",
    "| latitude | numeric |  | WGS84 latitude |\n",
    "| longitude | numeric |  | WGS84 longitude |\n",
    "| property_type | text |  | Self-selected property type |\n",
    "| room_type | text |  | One of:<br>\u2022 **Entire home/apt** \u2014 Whole space<br>\u2022 **Private room** \u2014 Own room, shared areas<br>\u2022 **Shared room** \u2014 Shared sleeping space |\n",
    "| accommodates | integer |  | Max guest capacity |\n",
    "| bathrooms | numeric |  | Number of bathrooms |\n",
    "| bathrooms_text | string |  | Text description of bathrooms (legacy field) |\n",
    "| bedrooms | integer |  | Number of bedrooms |\n",
    "| beds | integer |  | Number of beds |\n",
    "| amenities | json |  | JSON array of amenities |\n",
    "| price | currency |  | Daily price (ignore `$` artifact) |\n",
    "| minimum_nights | integer |  | Minimum nights allowed |\n",
    "| maximum_nights | integer |  | Maximum nights allowed |\n",
    "| minimum_minimum_nights | integer | \u2705 | Smallest min nights (calendar, 365 days ahead) |\n",
    "| maximum_minimum_nights | integer | \u2705 | Largest min nights (calendar, 365 days ahead) |\n",
    "| minimum_maximum_nights | integer | \u2705 | Smallest max nights (calendar, 365 days ahead) |\n",
    "| maximum_maximum_nights | integer | \u2705 | Largest max nights (calendar, 365 days ahead) |\n",
    "| minimum_nights_avg_ntm | numeric | \u2705 | Avg min nights (calendar, 365 days ahead) |\n",
    "| maximum_nights_avg_ntm | numeric | \u2705 | Avg max nights (calendar, 365 days ahead) |\n",
    "| calendar_updated | date |  |  |\n",
    "| has_availability | boolean |  | *(t=true; f=false)* |\n",
    "| availability_30 | integer | \u2705 | Available nights (next 30 days) |\n",
    "| availability_60 | integer | \u2705 | Available nights (next 60 days) |\n",
    "| availability_90 | integer | \u2705 | Available nights (next 90 days) |\n",
    "| availability_365 | integer | \u2705 | Available nights (next 365 days) |\n",
    "| calendar_last_scraped | date |  |  |\n",
    "| number_of_reviews | integer |  | Total number of reviews |\n",
    "| number_of_reviews_ltm | integer | \u2705 | Reviews in last 12 months |\n",
    "| number_of_reviews_l30d | integer | \u2705 | Reviews in last 30 days |\n",
    "| first_review | date | \u2705 | Date of first review |\n",
    "| last_review | date | \u2705 | Date of most recent review |\n",
    "| review_scores_rating | numeric |  |  |\n",
    "| review_scores_accuracy | numeric |  |  |\n",
    "| review_scores_cleanliness | numeric |  |  |\n",
    "| review_scores_checkin | numeric |  |  |\n",
    "| review_scores_communication | numeric |  |  |\n",
    "| review_scores_location | numeric |  |  |\n",
    "| review_scores_value | numeric |  |  |\n",
    "| license | text |  | Licence/permit/registration number |\n",
    "| instant_bookable | boolean |  | *(t=true; f=false)* \u2014 Guests can book instantly |\n",
    "| calculated_host_listings_count | integer | \u2705 | Number of listings host has in this scrape (city/region) |\n",
    "| calculated_host_listings_count_entire_homes | integer | \u2705 | Entire homes owned by host |\n",
    "| calculated_host_listings_count_private_rooms | integer | \u2705 | Private rooms owned by host |\n",
    "| calculated_host_listings_count_shared_rooms | integer | \u2705 | Shared rooms owned by host |\n",
    "| reviews_per_month | numeric | \u2705 | Average reviews per month over listing lifetime.<br><br>**Pseudocode/SQL:**<br>`IF scrape_date - first_review <= 30 THEN number_of_reviews`<br>`ELSE number_of_reviews / ((scrape_date - first_review + 1) / (365/12))` |\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "\u2705 = Calculated field  \n",
    "\ud83d\udcd8 *Boolean values*: `t=true`, `f=false`  \n",
    "\ud83c\udf10 *Coordinates*: WGS84 projection  \n",
    "\ud83d\udca1 *Source*: [Inside Airbnb](http://insideairbnb.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bee25931a98b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "pd.set_option('display.max_columns', 80)\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "\n",
    "DATA_PATH = Path('listings_big.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7223d5b4bcbea66",
   "metadata": {},
   "source": [
    "## 1. Carga y saneamiento inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb419f7b184500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\n",
    "    DATA_PATH,\n",
    "    na_values=(\"N/A\", \"NA\", \"na\", \"n/a\", \"\"),\n",
    "    keep_default_na=True\n",
    ")\n",
    "\n",
    "df = df_raw.copy()\n",
    "# Limpieza de precios: eliminar s\u00edmbolos y convertir a num\u00e9rico\n",
    "df['price'] = (df['price']\n",
    "               .astype(str)\n",
    "               .str.replace(r'[\u20ac$\u00a3,]', '', regex=True)\n",
    "               .str.strip())\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "# Conversi\u00f3n de columnas fecha para posteriores features\n",
    "date_columns = ['last_scraped', 'host_since', 'first_review', 'last_review']\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "# Normalizaci\u00f3n de flags binarias\n",
    "def to_bool(series):\n",
    "    mapped = series.map({'t': 'yes', 'f': 'no', np.nan: 'no'})\n",
    "    return mapped.astype('object')\n",
    "for col in ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable', 'has_availability']:\n",
    "    if col in df.columns:\n",
    "        df[col] = to_bool(df[col])\n",
    "print(f\"Shape original: {df_raw.shape}\")\n",
    "print(f\"Shape despu\u00e9s de transformaciones b\u00e1sicas: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c1af9",
   "metadata": {},
   "source": [
    "### 1.0 Limpieza y escalado del precio\n",
    "\n",
    "Diagnosticamos si existen precios en cero/negativos, los imputamos con la mediana positiva y preparamos una versi\u00f3n escalada (`price_imputed`) compatible con MinMaxScaler para usar en el pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagn\u00f3stico y correcci\u00f3n de precios no positivos\n",
    "price_zero_count = (df['price'] == 0).sum()\n",
    "price_negative_count = (df['price'] < 0).sum()\n",
    "print(f'Precios iguales a 0: {price_zero_count}')\n",
    "print(f'Precios negativos: {price_negative_count}')\n",
    "positive_prices = df.loc[df['price'] > 0, 'price']\n",
    "if positive_prices.empty:\n",
    "    raise ValueError('No hay precios positivos disponibles para imputar.')\n",
    "median_positive_price = positive_prices.median()\n",
    "if price_zero_count + price_negative_count > 0:\n",
    "    print(f\"Imputando precios no positivos con la mediana de valores positivos: {median_positive_price:.2f}\")\n",
    "df['price_imputed'] = df['price'].mask(df['price'] <= 0, median_positive_price)\n",
    "print(f\"Precio m\u00ednimo tras imputaci\u00f3n: {df['price_imputed'].min():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d4fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos el rango tras aplicar MinMaxScaler sobre el precio imputado\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "price_scaler = MinMaxScaler()\n",
    "price_scaled_preview = price_scaler.fit_transform(df[['price_imputed']])\n",
    "print(f\"Rango del precio escalado: min={price_scaled_preview.min():.3f}, max={price_scaled_preview.max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78234f3be32a84f2",
   "metadata": {},
   "source": [
    "### 1.1 Informaci\u00f3n general del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eda02fc38c07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa114c31166fabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de tipos de columnas y conteo por tipo\n",
    "type_summary = df.dtypes.value_counts().rename('count').to_frame()\n",
    "type_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea784b5d082afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad\u00edsticas descriptivas de variables num\u00e9ricas\n",
    "def format_numeric_summary(df, exclude_patterns=(\"id\",), currency_cols=None, decimals=4):\n",
    "    # excluir columnas que no tienen sentido estad\u00edstico\n",
    "    columns_to_exclude = [c for c in df.columns if any(pat in c.lower() for pat in exclude_patterns)]\n",
    "    summary_num = (\n",
    "        df.drop(columns=columns_to_exclude)\n",
    "          .select_dtypes(include=\"number\")\n",
    "          .describe()\n",
    "          .T\n",
    "          .round(decimals)\n",
    "    )\n",
    "\n",
    "    # versi\u00f3n formateada\n",
    "    summary_fmt = summary_num.copy().astype(object)\n",
    "\n",
    "    # aplicar formato a las currency_cols\n",
    "    if currency_cols:\n",
    "        for col in currency_cols:\n",
    "            if col in summary_fmt.index:\n",
    "                summary_fmt.loc[col] = summary_num.loc[col].apply(lambda x: f\"${x:,.{decimals}f}\")\n",
    "\n",
    "    return summary_num, summary_fmt\n",
    "\n",
    "columns_to_exclude = [\"id\", \"scrape_id\", \"host_id\", \"calendar_updated\",\"neighbourhood_group_cleansed\"]\n",
    "currency_cols = [\"price\", \"estimated_revenue_l365d\"]\n",
    "\n",
    "numeric_summary, numeric_summary_fmt = format_numeric_summary(\n",
    "    df,\n",
    "    exclude_patterns=columns_to_exclude,\n",
    "    currency_cols=currency_cols,\n",
    "    decimals=2\n",
    ")\n",
    "\n",
    "numeric_summary_fmt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835083db1bfeab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad\u00edsticas b\u00e1sicas de variables categ\u00f3ricas/cadenas\n",
    "categorical_cols = df.select_dtypes(include=['object', 'string']).columns\n",
    "categorical_summary = df[categorical_cols].describe().T\n",
    "categorical_summary_sorted = categorical_summary.sort_values(\"freq\", ascending=False)\n",
    "\n",
    "categorical_summary_sorted.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059bbaf46d8ae38",
   "metadata": {},
   "source": [
    "\n",
    "### 1.2 Exploraci\u00f3n de duplicados y consistencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df10eefc4e7b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_count = df.duplicated(subset=['id']).sum()\n",
    "print(f\"Duplicados basados en 'id': {duplicate_count}\")\n",
    "\n",
    "missing_ids = df['id'].isna().sum()\n",
    "print(f\"IDs faltantes: {missing_ids}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d47119e0c3b695",
   "metadata": {},
   "source": [
    "## 2. Valores faltantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40127bb7b17211",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_abs = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (missing_abs / len(df)).round(4)\n",
    "missing_table = pd.DataFrame({'missing': missing_abs, 'percent': missing_pct})\n",
    "missing_table.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4724d2b20537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci\u00f3n del top de variables con mayor porcentaje de faltantes\n",
    "top_missing = missing_table[missing_table['percent'] > 0].head(25)\n",
    "ax = top_missing.sort_values('percent').plot.barh(y='percent', figsize=(8, 6))\n",
    "ax.set_xlabel('Proporci\u00f3n de valores faltantes')\n",
    "ax.set_ylabel('Variable')\n",
    "ax.set_title('Variables con mayor proporci\u00f3n de valores faltantes')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2bcf879481d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de missingness para detectar patrones\n",
    "try:\n",
    "    import missingno as msno\n",
    "    msno.matrix(df[['price', 'reviews_per_month', 'last_review', 'description', 'host_about', 'bathrooms']])\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print('missingno no est\u00e1 disponible en el entorno actual.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7760f154ad52a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de an\u00e1lisis MAR/MNAR: comparar reviews_per_month faltante vs n\u00famero de reviews\n",
    "reviews_missing_flag = df['reviews_per_month'].isna()\n",
    "comparison = df.groupby(reviews_missing_flag)['number_of_reviews'].agg(['mean', 'median', 'count'])\n",
    "comparison.index = ['reviews_per_month disponible', 'reviews_per_month faltante']\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146491e8c7c7d8a",
   "metadata": {},
   "source": [
    "**Interpretaci\u00f3n inicial:** La ausencia de `reviews_per_month` suele darse en listados sin rese\u00f1as recientes, sugiriendo un mecanismo MAR (dependiente de `number_of_reviews`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc17e620b083b80",
   "metadata": {},
   "source": [
    "## 3. Distribuciones y visualizaciones clave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c643c790aa35f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['price'].dropna(), bins=100, kde=True)\n",
    "plt.title('Distribuci\u00f3n de precios (todas las observaciones)')\n",
    "plt.xlabel('Precio por noche (USD)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff5f95d5d3e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci\u00f3n recortando el 1% superior para atenuar outliers\n",
    "price_cap = df['price'].quantile(0.99)\n",
    "sns.histplot(df.loc[df['price'] <= price_cap, 'price'], bins=60, kde=True)\n",
    "plt.axvline(df['price'].median(), color='red', linestyle='--', label='Mediana')\n",
    "plt.title('Distribuci\u00f3n de precios (<= percentil 99)')\n",
    "plt.xlabel('Precio por noche (USD)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20726be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness de precios para evaluar la asimetr\u00eda\n",
    "price_series = df['price'].dropna()\n",
    "price_skew = price_series.skew()\n",
    "positive_prices = price_series[price_series > 0]\n",
    "price_log_skew = np.log1p(positive_prices).skew() if not positive_prices.empty else np.nan\n",
    "print(f'Skewness (precio bruto): {price_skew:.3f}')\n",
    "print(f'Skewness (log1p del precio): {price_log_skew:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ceaaa14fe0d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x='room_type', y='price')\n",
    "plt.yscale('log')\n",
    "plt.title('Precio por tipo de habitaci\u00f3n (escala log)')\n",
    "plt.xlabel('Tipo de habitaci\u00f3n')\n",
    "plt.ylabel('Precio (log)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476813101b529aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precio vs capacidad\n",
    "sns.scatterplot(data=df, x='accommodates', y='price', hue='room_type', alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.title('Precio vs hu\u00e9spedes admitidos')\n",
    "plt.xlabel('Capacidad (accommodates)')\n",
    "plt.ylabel('Precio (log)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4315ad55a877098",
   "metadata": {},
   "source": [
    "### Distribuciones de disponibilidad y ocupaci\u00f3n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f746b15505086dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['availability_365'], bins=40, kde=False)\n",
    "plt.title('Distribuci\u00f3n de disponibilidad anual (d\u00edas disponibles)')\n",
    "plt.xlabel('D\u00edas disponibles en 365')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de569cd7c2989ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(1 - (df['availability_365'] / 365), bins=40, kde=True)\n",
    "plt.title('Tasa de ocupaci\u00f3n anual estimada')\n",
    "plt.xlabel('Proporci\u00f3n de noches ocupadas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ef8e0dadffc05",
   "metadata": {},
   "source": [
    "### Correlaci\u00f3n orientada a disponibilidad (categ\u00f3ricas codificadas)\n",
    "Para estudiar los drivers de disponibilidad aplicamos one-hot encoding sobre las variables categ\u00f3ricas y analizamos la correlaci\u00f3n con las tasas de ocupaci\u00f3n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7204b67c047a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificaci\u00f3n de categ\u00f3ricas para matriz de correlaci\u00f3n orientada a disponibilidad\n",
    "availability_cols = ['availability_30', 'availability_60', 'availability_90', 'availability_365']\n",
    "base_columns = ['accommodates', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights',\n",
    "                'number_of_reviews', 'reviews_per_month', 'price']\n",
    "\n",
    "corr_base = df[base_columns + availability_cols].copy()\n",
    "\n",
    "for horizon in [30, 60, 90, 365]:\n",
    "    rate_col = f'occupancy_rate_{horizon}'\n",
    "    if rate_col not in df.columns:\n",
    "        df[rate_col] = 1 - (df[f'availability_{horizon}'] / horizon)\n",
    "    corr_base[rate_col] = df[rate_col]\n",
    "\n",
    "binary_map = {'yes': 1, 'no': 0}\n",
    "for col in ['host_is_superhost', 'instant_bookable']:\n",
    "    corr_base[f'{col}_flag'] = df[col].map(binary_map)\n",
    "\n",
    "categorical_for_corr = ['room_type', 'property_type', 'neighbourhood_cleansed']\n",
    "corr_encoded = pd.get_dummies(\n",
    "    pd.concat([corr_base, df[categorical_for_corr]], axis=1),\n",
    "    columns=categorical_for_corr,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "corr_matrix = corr_encoded.corr(numeric_only=True)\n",
    "target_corr = corr_matrix[['availability_365', 'occupancy_rate_365']].sort_values(\n",
    "    by='occupancy_rate_365', ascending=False\n",
    ")\n",
    "\n",
    "top_features = target_corr.head(15).index\n",
    "sns.heatmap(\n",
    "    corr_matrix.loc[top_features, ['availability_365', 'occupancy_rate_365']],\n",
    "    annot=True, fmt='.2f', cmap='coolwarm', vmin=-1, vmax=1\n",
    ")\n",
    "plt.title('Correlaci\u00f3n con disponibilidad y ocupaci\u00f3n (top 15)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "target_corr.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004950f139aa933",
   "metadata": {},
   "source": [
    "## 4. Disponibilidad y objetivo de ocupaci\u00f3n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408233e09485433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C\u00e1lculo de tasas de ocupaci\u00f3n a partir de la disponibilidad\n",
    "availability_cols = ['availability_30', 'availability_60', 'availability_90', 'availability_365']\n",
    "occupancy_df = df[availability_cols].copy()\n",
    "\n",
    "for horizon in [30, 60, 90, 365]:\n",
    "    rate_col = f'occupancy_rate_{horizon}'\n",
    "    df[rate_col] = 1 - (df[f'availability_{horizon}'] / horizon)\n",
    "    occupancy_df[rate_col] = df[rate_col]\n",
    "\n",
    "occupancy_summary = occupancy_df[[f'occupancy_rate_{h}' for h in [30, 60, 90, 365]]].describe().T\n",
    "print(occupancy_summary[['mean', 'std', 'min', '25%', '50%', '75%', 'max']])\n",
    "\n",
    "# Target multiclase basado en la tasa anual\n",
    "bins = [0.0, 0.4, 0.7, 1.01]\n",
    "labels = ['low', 'mid', 'high']\n",
    "df['occupancy_level'] = pd.cut(\n",
    "    df['occupancy_rate_365'].clip(lower=0, upper=1),\n",
    "    bins=bins, labels=labels, right=False, include_lowest=True\n",
    ")\n",
    "\n",
    "level_counts = df['occupancy_level'].value_counts(dropna=False).sort_index()\n",
    "print('Distribuci\u00f3n de occupancy_level:')\n",
    "print(level_counts)\n",
    "print('Proporciones:')\n",
    "print((level_counts / len(df)).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964cff18e07837d7",
   "metadata": {},
   "source": [
    "**Decisi\u00f3n:** Se utilizar\u00e1 la etiqueta multiclase `occupancy_level` para representar la ocupaci\u00f3n esperada (low/mid/high). El objetivo del modelado es predecir este nivel sin emplear variables de disponibilidad futuras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bf4f62eef30519",
   "metadata": {},
   "source": [
    "## 5. Planteo del problema supervisado\n",
    "Planteamos un problema de **clasificaci\u00f3n multiclase** donde la variable target es `occupancy_level`, construida a partir de la tasa de ocupaci\u00f3n anual estimada. Los niveles son:\n",
    "- `high`: ocupaci\u00f3n >= 70%\n",
    "- `mid`: ocupaci\u00f3n entre 40% y 70%\n",
    "- `low`: ocupaci\u00f3n < 40%\n",
    "\n",
    "El objetivo es anticipar la categor\u00eda de ocupaci\u00f3n utilizando \u00fanicamente atributos conocidos al momento de publicar un listing (sin recurrir a disponibilidades futuras). Se evaluar\u00e1 con m\u00e9tricas como F1 macro, balanced accuracy y matrices de confusi\u00f3n para garantizar buen desempe\u00f1o en las tres clases.\n",
    "\n",
    "Las features consideradas combinan atributos de ubicaci\u00f3n (`latitude`, `longitude`, `neighbourhood_cleansed`), configuraci\u00f3n (`room_type`, `property_type`, `accommodates`, `bedrooms`), reputaci\u00f3n (`number_of_reviews`, `reviews_per_month`, `host_is_superhost`) y m\u00e9tricas derivadas de la actividad del host (`host_tenure_days`, `reviews_per_year`, `days_since_last_review`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb421fe95701f7c",
   "metadata": {},
   "source": [
    "**Definici\u00f3n del target:** `occupancy_level` surge de discretizar la tasa de ocupaci\u00f3n anual en tres bandas (`low`, `mid`, `high`) con umbrales (0.0, 0.4, 0.7, 1.0]. Esto permite capturar distintos perfiles de demanda y evita depender de la disponibilidad futura como feature. Registros sin informaci\u00f3n suficiente quedan con valor nulo y se descartan durante el split de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc238435e820dab",
   "metadata": {},
   "source": [
    "## 6. Ingenier\u00eda de features y preprocesamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae6ac0b",
   "metadata": {},
   "source": [
    "### 6.1 Codificaci\u00f3n de amenities\n",
    "\n",
    "Normalizamos la columna JSON de `amenities`, homogenizamos etiquetas y generamos indicadores binarios para las 20 amenidades m\u00e1s frecuentes; estas columnas (`amenity_*`) ampl\u00edan el set de features con informaci\u00f3n interpretable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42876f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos la columna de amenities y generamos indicadores binarios\n",
    "def normalize_amenities(value):\n",
    "    if pd.isna(value):\n",
    "        return []\n",
    "    text = str(value).strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    candidate = text.replace('{', '[').replace('}', ']')\n",
    "    try:\n",
    "        parsed = json.loads(candidate)\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            parsed = ast.literal_eval(candidate)\n",
    "        except (ValueError, SyntaxError):\n",
    "            parsed = [item.strip() for item in candidate.strip('[]').split(',')]\n",
    "    normalized = []\n",
    "    for item in parsed:\n",
    "        token = str(item).strip().strip('\"').strip(\"'\")\n",
    "        if token:\n",
    "            normalized.append(token.lower())\n",
    "    return sorted(set(normalized))\n",
    "\n",
    "amenity_lists = df['amenities'].apply(normalize_amenities)\n",
    "amenity_counts = amenity_lists.explode().value_counts()\n",
    "top_k = 20\n",
    "top_amenities = amenity_counts.head(top_k)\n",
    "\n",
    "def amenity_to_col(amenity):\n",
    "    slug = re.sub(r'[^a-z0-9]+', '_', amenity).strip('_')\n",
    "    return f'amenity_{slug}' if slug else 'amenity_other'\n",
    "\n",
    "amenities_feature_cols = []\n",
    "for amenity in top_amenities.index:\n",
    "    base_name = amenity_to_col(amenity)\n",
    "    name = base_name\n",
    "    suffix = 1\n",
    "    while name in amenities_feature_cols:\n",
    "        suffix += 1\n",
    "        name = f\"{base_name}_{suffix}\"\n",
    "    amenities_feature_cols.append(name)\n",
    "    df[name] = amenity_lists.apply(lambda items, target=amenity: int(target in items))\n",
    "\n",
    "top_amenities.to_frame(name='count').assign(percent=lambda data: data['count'] / len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c7b3a1fa4791c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering orientado a ocupaci\u00f3n\n",
    "# Imputar rese\u00f1as por mes faltantes con 0 (sugiere ausencia de rese\u00f1as)\n",
    "df['reviews_per_month_filled'] = df['reviews_per_month'].fillna(0)\n",
    "\n",
    "# Antig\u00fcedad del host y tiempo desde la \u00faltima rese\u00f1a\n",
    "reference_date = df['last_scraped'].max()\n",
    "df['host_tenure_days'] = (reference_date - df['host_since']).dt.days\n",
    "\n",
    "df['days_since_last_review'] = (reference_date - df['last_review']).dt.days\n",
    "\n",
    "# Densidad de rese\u00f1as: reviews acumulados sobre tenure (evitar divisi\u00f3n por cero)\n",
    "df['reviews_per_year'] = df['number_of_reviews'] / (df['host_tenure_days'] / 365)\n",
    "df.loc[df['host_tenure_days'] <= 0, 'reviews_per_year'] = np.nan\n",
    "\n",
    "# Construimos dataset sin columnas de disponibilidad para evitar fuga de informaci\u00f3n\n",
    "amenities_feature_cols = globals().get('amenities_feature_cols', [])\n",
    "base_feature_cols = [\n",
    "    'accommodates', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights',\n",
    "    'price_imputed',\n",
    "    'number_of_reviews', 'reviews_per_month_filled', 'latitude', 'longitude',\n",
    "    'host_is_superhost', 'instant_bookable', 'room_type', 'property_type',\n",
    "    'neighbourhood_cleansed', 'host_tenure_days', 'days_since_last_review', 'reviews_per_year'\n",
    "]\n",
    "\n",
    "feature_cols = base_feature_cols + amenities_feature_cols\n",
    "\n",
    "model_df = df[feature_cols + ['occupancy_level']].copy()\n",
    "model_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f76e60a81f91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'occupancy_level'\n",
    "X = model_df.drop(columns=[target_col])\n",
    "y = model_df[target_col]\n",
    "\n",
    "print(f'Observaciones totales para modelado: {len(X)}')\n",
    "print(f'Registros sin target: {y.isna().sum()} (ser\u00e1n descartados antes del split)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd52dc157ac91f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "valid_rows = y.notna()\n",
    "X_valid = X.loc[valid_rows]\n",
    "y_valid = y.loc[valid_rows]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_valid, y_valid, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b77e9176c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "amenities_feature_cols = globals().get('amenities_feature_cols', [])\n",
    "\n",
    "numeric_features = [\n",
    "    'accommodates', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights',\n",
    "    'number_of_reviews', 'reviews_per_month_filled', 'latitude', 'longitude',\n",
    "    'host_tenure_days', 'days_since_last_review', 'reviews_per_year'\n",
    "]\n",
    "\n",
    "numeric_features += amenities_feature_cols\n",
    "\n",
    "price_feature = ['price_imputed']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "price_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_features = [\n",
    "    'host_is_superhost', 'instant_bookable', 'room_type', 'property_type', 'neighbourhood_cleansed'\n",
    "]\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('price', price_transformer, price_feature),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "X_test_prepared = preprocessor.transform(X_test)\n",
    "\n",
    "print(f'Matriz transformada - train: {X_train_prepared.shape}')\n",
    "print(f'Matriz transformada - test: {X_test_prepared.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99448b336295781",
   "metadata": {},
   "source": [
    "### Balance del target (low/mid/high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321e0bb9c802309",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True).sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34654b45708c00",
   "metadata": {},
   "source": [
    "## 7. Selecci\u00f3n y reducci\u00f3n de dimensionalidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6660485180d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de features num\u00e9ricas (ANOVA F-score)\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "numeric_matrix = preprocessor.named_transformers_['num'].transform(X_train[numeric_features])\n",
    "f_scores, p_values = f_classif(numeric_matrix, y_train)\n",
    "\n",
    "anova_scores = (pd.Series(f_scores, index=numeric_features)\n",
    "                  .sort_values(ascending=False))\n",
    "anova_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c969dcd37b172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "numeric_matrix = preprocessor.named_transformers_['num'].transform(X_train[numeric_features])\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=min(8, len(numeric_features)))\n",
    "selector.fit(numeric_matrix, y_train)\n",
    "\n",
    "selected_numeric = [numeric_features[i] for i in selector.get_support(indices=True)]\n",
    "print('Mejores features num\u00e9ricas seg\u00fan mutual information:', selected_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347058c790bf80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Aplicamos PCA sobre features num\u00e9ricas estandarizadas\n",
    "numeric_imputed = preprocessor.named_transformers_['num'].fit_transform(X_train[numeric_features])\n",
    "pca = PCA().fit(numeric_imputed)\n",
    "explained_variance = pd.DataFrame({\n",
    "    'componente': np.arange(1, len(pca.explained_variance_ratio_) + 1),\n",
    "    'var_ratio': pca.explained_variance_ratio_,\n",
    "    'var_acumulada': np.cumsum(pca.explained_variance_ratio_)\n",
    "})\n",
    "explained_variance.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137d2dfed424850",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(explained_variance['componente'], explained_variance['var_acumulada'], marker='o')\n",
    "plt.xlabel('N\u00famero de componentes')\n",
    "plt.ylabel('Varianza acumulada')\n",
    "plt.title('Curva de varianza explicada por PCA')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be563a7ec03983f",
   "metadata": {},
   "source": [
    "**Interpretaci\u00f3n:** Con ~6 componentes se retiene alrededor del 80% de la varianza num\u00e9rica, \u00fatil si se necesita compactar el espacio antes de entrenar clasificadores sensibles a la dimensionalidad (p. ej. regresi\u00f3n log\u00edstica).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbb9165d364d34",
   "metadata": {},
   "source": [
    "## 8. Pr\u00f3ximos pasos sugeridos\n",
    "- Entrenar clasificadores multiclase (`LogisticRegression`, `RandomForestClassifier`, `XGBoost`) usando el pipeline de `preprocessor`.\n",
    "- Medir F1 macro, balanced accuracy y analizar la matriz de confusi\u00f3n para los niveles `low/mid/high`.\n",
    "- Ajustar umbrales o reglas de decisi\u00f3n seg\u00fan la estrategia comercial (p. ej. priorizar recall de `high`).\n",
    "- Incorporar nuevas variables disponibles al crear el anuncio (amenities, pol\u00edticas, texto) para mejorar el poder predictivo sin depender de disponibilidad futura.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acd2c9ae00d013",
   "metadata": {},
   "source": [
    "- Entrenar un modelo base (p. ej. `RandomForestRegressor`, `GradientBoostingRegressor`) usando el pipeline de `preprocessor`.\n",
    "- Validar con una m\u00e9trica robusta (MAE) y comparar contra un baseline como la mediana.\n",
    "- Explorar ingenier\u00eda espec\u00edfica del vecindario (densidad de listings, precio medio por zona) y disponibilidad.\n",
    "- Evaluar estrategias de tuning (GridSearch/Optuna) y monitoreo de drift con `wandb`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}