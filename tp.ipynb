{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64ee407",
   "metadata": {},
   "source": [
    "# Trabajo Práctico: Exploración y Preparación de Airbnb Listings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa45038",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "En esta libreta analizamos el dataset `listings_big.csv` para comprender su estructura, diagnosticar problemas de calidad y preparar un conjunto de features apto para estimar **qué tan alquilable es un listing**. El flujo general incluye:\n",
    "- Exploración inicial y resumen estadístico\n",
    "- Análisis de valores faltantes y patrones de disponibilidad\n",
    "- Visualizaciones que permitan interpretar la ocupación y sus drivers\n",
    "- Definición de un problema supervisado de clasificación enfocado en la alta ocupación\n",
    "- Construcción de un pipeline de preprocesamiento, ingeniería de variables y selección/reducción de dimensionalidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eac4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "pd.set_option('display.max_columns', 80)\n",
    "\n",
    "DATA_PATH = Path('listings_big.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60609f7e",
   "metadata": {},
   "source": [
    "## 1. Carga y saneamiento inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d53cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "df = df_raw.copy()\n",
    "# Limpieza de precios: eliminar símbolos y convertir a numérico\n",
    "df['price'] = (df['price']\n",
    "               .astype(str)\n",
    "               .str.replace(r'[€$£,]', '', regex=True)\n",
    "               .str.strip())\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "# Conversión de columnas fecha para posteriores features\n",
    "date_columns = ['last_scraped', 'host_since', 'first_review', 'last_review']\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "# Normalización de flags binarias\n",
    "def to_bool(series):\n",
    "    mapped = series.map({'t': 'yes', 'f': 'no'})\n",
    "    return mapped.astype('object')\n",
    "for col in ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable', 'has_availability']:\n",
    "    if col in df.columns:\n",
    "        df[col] = to_bool(df[col])\n",
    "print(f\"Shape original: {df_raw.shape}\")\n",
    "print(f\"Shape después de transformaciones básicas: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b3ed2",
   "metadata": {},
   "source": [
    "### 1.1 Información general del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be29563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de tipos de columnas y conteo por tipo\n",
    "type_summary = df.dtypes.value_counts().rename('count').to_frame()\n",
    "type_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de variables numéricas\n",
    "numeric_summary = df.select_dtypes(include=[np.number]).describe().T\n",
    "numeric_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e6527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas básicas de variables categóricas/cadenas\n",
    "categorical_cols = df.select_dtypes(include=['object', 'string']).columns\n",
    "categorical_summary = df[categorical_cols].describe().T\n",
    "categorical_summary.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a08c2",
   "metadata": {},
   "source": [
    "### 1.2 Exploración de duplicados y consistencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb6fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_count = df.duplicated(subset=['id']).sum()\n",
    "print(f\"Duplicados basados en 'id': {duplicate_count}\")\n",
    "\n",
    "missing_ids = df['id'].isna().sum()\n",
    "print(f\"IDs faltantes: {missing_ids}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b355f6",
   "metadata": {},
   "source": [
    "## 2. Valores faltantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_abs = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (missing_abs / len(df)).round(4)\n",
    "missing_table = pd.DataFrame({'missing': missing_abs, 'percent': missing_pct})\n",
    "missing_table.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del top de variables con mayor porcentaje de faltantes\n",
    "top_missing = missing_table[missing_table['percent'] > 0].head(25)\n",
    "ax = top_missing.sort_values('percent').plot.barh(y='percent', figsize=(8, 6))\n",
    "ax.set_xlabel('Proporción de valores faltantes')\n",
    "ax.set_ylabel('Variable')\n",
    "ax.set_title('Variables con mayor proporción de valores faltantes')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de missingness para detectar patrones\n",
    "try:\n",
    "    import missingno as msno\n",
    "    msno.matrix(df[['price', 'reviews_per_month', 'last_review', 'description', 'host_about', 'bathrooms']])\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print('missingno no está disponible en el entorno actual.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22517573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de análisis MAR/MNAR: comparar reviews_per_month faltante vs número de reviews\n",
    "reviews_missing_flag = df['reviews_per_month'].isna()\n",
    "comparison = df.groupby(reviews_missing_flag)['number_of_reviews'].agg(['mean', 'median', 'count'])\n",
    "comparison.index = ['reviews_per_month disponible', 'reviews_per_month faltante']\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc9bb4",
   "metadata": {},
   "source": [
    "**Interpretación inicial:** La ausencia de `reviews_per_month` suele darse en listados sin reseñas recientes, sugiriendo un mecanismo MAR (dependiente de `number_of_reviews`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb5eb1",
   "metadata": {},
   "source": [
    "## 3. Distribuciones y visualizaciones clave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69abc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['price'].dropna(), bins=100, kde=True)\n",
    "plt.title('Distribución de precios (todas las observaciones)')\n",
    "plt.xlabel('Precio por noche (USD)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd285c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución recortando el 1% superior para atenuar outliers\n",
    "price_cap = df['price'].quantile(0.99)\n",
    "sns.histplot(df.loc[df['price'] <= price_cap, 'price'], bins=60, kde=True)\n",
    "plt.axvline(df['price'].median(), color='red', linestyle='--', label='Mediana')\n",
    "plt.title('Distribución de precios (<= percentil 99)')\n",
    "plt.xlabel('Precio por noche (USD)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8358369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x='room_type', y='price')\n",
    "plt.yscale('log')\n",
    "plt.title('Precio por tipo de habitación (escala log)')\n",
    "plt.xlabel('Tipo de habitación')\n",
    "plt.ylabel('Precio (log)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precio vs capacidad\n",
    "sns.scatterplot(data=df, x='accommodates', y='price', hue='room_type', alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.title('Precio vs huéspedes admitidos')\n",
    "plt.xlabel('Capacidad (accommodates)')\n",
    "plt.ylabel('Precio (log)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af868d35",
   "metadata": {},
   "source": [
    "### Distribuciones de disponibilidad y ocupación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb548746",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['availability_365'], bins=40, kde=False)\n",
    "plt.title('Distribución de disponibilidad anual (días disponibles)')\n",
    "plt.xlabel('Días disponibles en 365')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(1 - (df['availability_365'] / 365), bins=40, kde=True)\n",
    "plt.title('Tasa de ocupación anual estimada')\n",
    "plt.xlabel('Proporción de noches ocupadas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca84826",
   "metadata": {},
   "source": [
    "### Correlación orientada a disponibilidad (categóricas codificadas)\n",
    "Para estudiar los drivers de disponibilidad aplicamos one-hot encoding sobre las variables categóricas y analizamos la correlación con las tasas de ocupación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06687b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de categóricas para matriz de correlación orientada a disponibilidad\n",
    "availability_cols = ['availability_30', 'availability_60', 'availability_90', 'availability_365']\n",
    "base_columns = ['accommodates', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights',\n",
    "                'number_of_reviews', 'reviews_per_month', 'price']\n",
    "\n",
    "corr_base = df[base_columns + availability_cols].copy()\n",
    "\n",
    "for horizon in [30, 60, 90, 365]:\n",
    "    rate_col = f'occupancy_rate_{horizon}'\n",
    "    if rate_col not in df.columns:\n",
    "        df[rate_col] = 1 - (df[f'availability_{horizon}'] / horizon)\n",
    "    corr_base[rate_col] = df[rate_col]\n",
    "\n",
    "binary_map = {'yes': 1, 'no': 0}\n",
    "for col in ['host_is_superhost', 'instant_bookable']:\n",
    "    corr_base[f'{col}_flag'] = df[col].map(binary_map)\n",
    "\n",
    "categorical_for_corr = ['room_type', 'property_type', 'neighbourhood_cleansed']\n",
    "corr_encoded = pd.get_dummies(\n",
    "    pd.concat([corr_base, df[categorical_for_corr]], axis=1),\n",
    "    columns=categorical_for_corr,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "corr_matrix = corr_encoded.corr(numeric_only=True)\n",
    "target_corr = corr_matrix[['availability_365', 'occupancy_rate_365']].sort_values(\n",
    "    by='occupancy_rate_365', ascending=False\n",
    ")\n",
    "\n",
    "top_features = target_corr.head(15).index\n",
    "sns.heatmap(\n",
    "    corr_matrix.loc[top_features, ['availability_365', 'occupancy_rate_365']],\n",
    "    annot=True, fmt='.2f', cmap='coolwarm', vmin=-1, vmax=1\n",
    ")\n",
    "plt.title('Correlación con disponibilidad y ocupación (top 15)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "target_corr.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a81cfb",
   "metadata": {},
   "source": [
    "## 4. Disponibilidad y objetivo de ocupación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd78be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de tasas de ocupación a partir de la disponibilidad\n",
    "availability_cols = ['availability_30', 'availability_60', 'availability_90', 'availability_365']\n",
    "occupancy_df = df[availability_cols].copy()\n",
    "\n",
    "for horizon in [30, 60, 90, 365]:\n",
    "    rate_col = f'occupancy_rate_{horizon}'\n",
    "    df[rate_col] = 1 - (df[f'availability_{horizon}'] / horizon)\n",
    "    occupancy_df[rate_col] = df[rate_col]\n",
    "\n",
    "occupancy_summary = occupancy_df[[f'occupancy_rate_{h}' for h in [30, 60, 90, 365]]].describe().T\n",
    "print(occupancy_summary[['mean', 'std', 'min', '25%', '50%', '75%', 'max']])\n",
    "\n",
    "# Target multiclase basado en la tasa anual\n",
    "bins = [0.0, 0.4, 0.7, 1.01]\n",
    "labels = ['low', 'mid', 'high']\n",
    "df['occupancy_level'] = pd.cut(\n",
    "    df['occupancy_rate_365'].clip(lower=0, upper=1),\n",
    "    bins=bins, labels=labels, right=False, include_lowest=True\n",
    ")\n",
    "\n",
    "level_counts = df['occupancy_level'].value_counts(dropna=False).sort_index()\n",
    "print('Distribución de occupancy_level:')\n",
    "print(level_counts)\n",
    "print('Proporciones:')\n",
    "print((level_counts / len(df)).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a98d8fd",
   "metadata": {},
   "source": [
    "**Decisión:** Se utilizará la etiqueta multiclase `occupancy_level` para representar la ocupación esperada (low/mid/high). El objetivo del modelado es predecir este nivel sin emplear variables de disponibilidad futuras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a22a5",
   "metadata": {},
   "source": [
    "## 5. Planteo del problema supervisado\n",
    "Planteamos un problema de **clasificación multiclase** donde la variable target es `occupancy_level`, construida a partir de la tasa de ocupación anual estimada. Los niveles son:\n",
    "- `high`: ocupación >= 70%\n",
    "- `mid`: ocupación entre 40% y 70%\n",
    "- `low`: ocupación < 40%\n",
    "\n",
    "El objetivo es anticipar la categoría de ocupación utilizando únicamente atributos conocidos al momento de publicar un listing (sin recurrir a disponibilidades futuras). Se evaluará con métricas como F1 macro, balanced accuracy y matrices de confusión para garantizar buen desempeño en las tres clases.\n",
    "\n",
    "Las features consideradas combinan atributos de ubicación (`latitude`, `longitude`, `neighbourhood_cleansed`), configuración (`room_type`, `property_type`, `accommodates`, `bedrooms`), reputación (`number_of_reviews`, `reviews_per_month`, `host_is_superhost`) y métricas derivadas de la actividad del host (`host_tenure_days`, `reviews_per_year`, `days_since_last_review`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d172e",
   "metadata": {},
   "source": [
    "**Definición del target:** `occupancy_level` surge de discretizar la tasa de ocupación anual en tres bandas (`low`, `mid`, `high`) con umbrales (0.0, 0.4, 0.7, 1.0]. Esto permite capturar distintos perfiles de demanda y evita depender de la disponibilidad futura como feature. Registros sin información suficiente quedan con valor nulo y se descartan durante el split de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16990dd",
   "metadata": {},
   "source": [
    "## 6. Ingeniería de features y preprocesamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering orientado a ocupación\n",
    "# Imputar reseñas por mes faltantes con 0 (sugiere ausencia de reseñas)\n",
    "df['reviews_per_month_filled'] = df['reviews_per_month'].fillna(0)\n",
    "\n",
    "# Antigüedad del host y tiempo desde la última reseña\n",
    "reference_date = df['last_scraped'].max()\n",
    "df['host_tenure_days'] = (reference_date - df['host_since']).dt.days\n",
    "\n",
    "df['days_since_last_review'] = (reference_date - df['last_review']).dt.days\n",
    "\n",
    "# Densidad de reseñas: reviews acumulados sobre tenure (evitar división por cero)\n",
    "df['reviews_per_year'] = df['number_of_reviews'] / (df['host_tenure_days'] / 365)\n",
    "df.loc[df['host_tenure_days'] <= 0, 'reviews_per_year'] = np.nan\n",
    "\n",
    "# Construimos dataset sin columnas de disponibilidad para evitar fuga de información\n",
    "feature_cols = [\n",
    "    'accommodates', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights',\n",
    "    'number_of_reviews', 'reviews_per_month_filled', 'latitude', 'longitude',\n",
    "    'host_is_superhost', 'instant_bookable', 'room_type', 'property_type',\n",
    "    'neighbourhood_cleansed', 'host_tenure_days', 'days_since_last_review', 'reviews_per_year'\n",
    "]\n",
    "\n",
    "model_df = df[feature_cols + ['occupancy_level']].copy()\n",
    "model_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ce001",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'occupancy_level'\n",
    "X = model_df.drop(columns=[target_col])\n",
    "y = model_df[target_col]\n",
    "\n",
    "print(f'Observaciones totales para modelado: {len(X)}')\n",
    "print(f'Registros sin target: {y.isna().sum()} (serán descartados antes del split)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40041449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "valid_rows = y.notna()\n",
    "X_valid = X.loc[valid_rows]\n",
    "y_valid = y.loc[valid_rows]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_valid, y_valid, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = [\n",
    "    'accommodates', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights',\n",
    "    'number_of_reviews', 'reviews_per_month_filled', 'latitude', 'longitude',\n",
    "    'host_tenure_days', 'days_since_last_review', 'reviews_per_year'\n",
    "]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = [\n",
    "    'host_is_superhost', 'instant_bookable', 'room_type', 'property_type', 'neighbourhood_cleansed'\n",
    "]\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "X_test_prepared = preprocessor.transform(X_test)\n",
    "\n",
    "print(f'Matriz transformada - train: {X_train_prepared.shape}')\n",
    "print(f'Matriz transformada - test: {X_test_prepared.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186dcad7",
   "metadata": {},
   "source": [
    "### Balance del target (low/mid/high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca727f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True).sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a8f86e",
   "metadata": {},
   "source": [
    "## 7. Selección y reducción de dimensionalidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec55401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de features numéricas (ANOVA F-score)\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "numeric_matrix = preprocessor.named_transformers_['num'].transform(X_train[numeric_features])\n",
    "f_scores, p_values = f_classif(numeric_matrix, y_train)\n",
    "\n",
    "anova_scores = (pd.Series(f_scores, index=numeric_features)\n",
    "                  .sort_values(ascending=False))\n",
    "anova_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa41292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "numeric_matrix = preprocessor.named_transformers_['num'].transform(X_train[numeric_features])\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=min(8, len(numeric_features)))\n",
    "selector.fit(numeric_matrix, y_train)\n",
    "\n",
    "selected_numeric = [numeric_features[i] for i in selector.get_support(indices=True)]\n",
    "print('Mejores features numéricas según mutual information:', selected_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Aplicamos PCA sobre features numéricas estandarizadas\n",
    "numeric_imputed = preprocessor.named_transformers_['num'].fit_transform(X_train[numeric_features])\n",
    "pca = PCA().fit(numeric_imputed)\n",
    "explained_variance = pd.DataFrame({\n",
    "    'componente': np.arange(1, len(pca.explained_variance_ratio_) + 1),\n",
    "    'var_ratio': pca.explained_variance_ratio_,\n",
    "    'var_acumulada': np.cumsum(pca.explained_variance_ratio_)\n",
    "})\n",
    "explained_variance.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(explained_variance['componente'], explained_variance['var_acumulada'], marker='o')\n",
    "plt.xlabel('Número de componentes')\n",
    "plt.ylabel('Varianza acumulada')\n",
    "plt.title('Curva de varianza explicada por PCA')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbbf4e3",
   "metadata": {},
   "source": [
    "**Interpretación:** Con ~6 componentes se retiene alrededor del 80% de la varianza numérica, útil si se necesita compactar el espacio antes de entrenar clasificadores sensibles a la dimensionalidad (p. ej. regresión logística).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475013b8",
   "metadata": {},
   "source": [
    "## 8. Próximos pasos sugeridos\n",
    "- Entrenar clasificadores multiclase (`LogisticRegression`, `RandomForestClassifier`, `XGBoost`) usando el pipeline de `preprocessor`.\n",
    "- Medir F1 macro, balanced accuracy y analizar la matriz de confusión para los niveles `low/mid/high`.\n",
    "- Ajustar umbrales o reglas de decisión según la estrategia comercial (p. ej. priorizar recall de `high`).\n",
    "- Incorporar nuevas variables disponibles al crear el anuncio (amenities, políticas, texto) para mejorar el poder predictivo sin depender de disponibilidad futura.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb292671",
   "metadata": {},
   "source": [
    "- Entrenar un modelo base (p. ej. `RandomForestRegressor`, `GradientBoostingRegressor`) usando el pipeline de `preprocessor`.\n",
    "- Validar con una métrica robusta (MAE) y comparar contra un baseline como la mediana.\n",
    "- Explorar ingeniería específica del vecindario (densidad de listings, precio medio por zona) y disponibilidad.\n",
    "- Evaluar estrategias de tuning (GridSearch/Optuna) y monitoreo de drift con `wandb`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
